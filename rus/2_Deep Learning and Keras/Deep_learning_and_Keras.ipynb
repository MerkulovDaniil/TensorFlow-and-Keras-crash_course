{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning and Keras crash course\n",
    "\n",
    "Daniil Merkulov\n",
    "\n",
    "Skoltech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites:\n",
    "* `pip install numpy`\n",
    "* `pip install tensorflow`\n",
    "* `pip install pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras: краткий обзор\n",
    "![](https://keras.io/img/keras-logo-small-wb.png)\n",
    "* Библиотека для машинного обучения (прежде всего, обучения нейронных сетей, в т.ч. глубоких). \n",
    "* Представляет собой удобную обертку для мощных и хорошо оптимизированных вычислительных библиотек: TensorFlow, Theano\n",
    "* Основные принципы: \n",
    "    1. Удобство использования\n",
    "    2. Модульность\n",
    "    3. Масштабируемость\n",
    "    4. Работа с Python\n",
    "    \n",
    "Инструмент с низким порогом входа, подходящий как продвинутым исследовалетям, так и энтузиастам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Возвращение MNIST. Сравнения\n",
    "Давайте вернемся к старой доброй задаче распознавания рукописных цифр, чтобы посмотреть сколько занимает код для такой нейросети, написанный на keras. Кроме того, здесь же мы попробуем собрать простую сверточную сеть для улучшения результата.\n",
    "\n",
    "### Классическая нейросеть с плотными (dense) слоями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "import keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузка данных. В keras уже есть несколько популярных датасетов, которые можно легко загрузить. Давайте загрузим MNIST\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Подготовка датасета: нормализация значений на [0,1] и перевод признаков в one-hot формат\n",
    "X_train, X_test = X_train/255, X_test/255\n",
    "y_train, y_test = keras.utils.to_categorical(y_train, 10), keras.utils.to_categorical(y_test, 10)\n",
    "input_size = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создание модели. Sequential здесь означает последовательный тип модели, в который мы добавляем слои друг за другом\n",
    "model = Sequential()\n",
    "\n",
    "# Добавляем в стек модели слой за слоем. Полносвязный, активация и т.д.\n",
    "# Важно: в первом слое Sequential модели keras необходимо указать размерность входных данных.\n",
    "model.add(Flatten(input_shape=input_size))\n",
    "model.add(Dense(units=256, input_shape=input_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s - loss: 0.6187 - acc: 0.8470     \n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s - loss: 0.3332 - acc: 0.9079     \n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s - loss: 0.2851 - acc: 0.9205     \n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s - loss: 0.2539 - acc: 0.9290     \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s - loss: 0.2297 - acc: 0.9355     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2751ac917f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# После описания архитектуры необходимо скомпилировать модель, указав минимизируемую функцию потерь, \n",
    "# оптимизатор и попросив модель выводить точность работы на тестовой выорке в процессе обучения\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Тренировка с указанием данных, числа эпох и размера подвыборки\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21461834994256496, 0.93879999999999997]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим качество работы модели на тестовых данных. Выводится loss и точночть.\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим сверточный слой и посмотрим на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "# Создание модели. Sequential здесь означает последовательный тип модели, в который мы добавляем слои друг за другом\n",
    "conv_model = Sequential()\n",
    "\n",
    "# Добавим явно число каналов в наш датасет - это важно для сверточных слоев. \n",
    "# т.е. делается преобразование (60000, 28, 28) -> (60000, 28, 28, 1). Это ничего не изменяет.\n",
    "X_train, X_test = X_train.reshape((60000, 28, 28, 1)), X_test.reshape((10000, 28, 28, 1))\n",
    "input_size = X_train[0].shape\n",
    "\n",
    "# Здесь мы используем сверточный слой, который тренирует 32 фильтра размером 3x3 для поиска \n",
    "# конкретных геометрических (настраиваемых в процессе обучения)паттернов на входном изображении.\n",
    "conv_model.add(Conv2D(24, (3, 3), input_shape=input_size))\n",
    "conv_model.add(Activation('selu'))\n",
    "conv_model.add(Flatten())\n",
    "conv_model.add(Dense(64, activation='selu'))\n",
    "conv_model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10816/30000 [=========>....................] - ETA: 34s - loss: 0.4272 - acc: 0.8696"
     ]
    }
   ],
   "source": [
    "# Поставим другой оптимизатор для разнообразия\n",
    "conv_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Тренировка с указанием данных, числа эпох и размера подвыборки\n",
    "conv_model.fit(X_train[:30000], y_train[:30000], epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим качество работы модели на тестовых данных. Выводится loss и точночть.\n",
    "conv_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверточные слои, dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируются и обучаются несколько фильтров небольших размеров так, чтобы распознавать какие то характерные сочетания пикселей (паттерны). Ниже на картинке изображение 5x5 пикселей, фильтр имеет размеры 3x3. При этом на выходе такой операции имеем картинку такого же размера, в каждый из пикселей которого записан результат свертки (число) данного фильтра с картинкой при нахождении центра фильтра в этом пикселе. Для этого исходную картинку необходимо дополнить по краям. Обычно это делают либо нулями, либо дублируют ближайшие пиксели (padding)\n",
    "![](convol.gif)\n",
    "\n",
    "Чем глубже сверточный слой, тем более сложные паттерны он способен распознавать:\n",
    "![](features.png)\n",
    "\n",
    "Dropout - техника спасения нейросетей от переобучения, при которой в процессе тренировки случайно \"выключаются\" некоторые нейроны из моделей.\n",
    "\n",
    "Альтернативный взгляд - вместо тренировки одной большой сети проходит одновременная тренировка нескольких подсетей меньшего размера, результаты которых потом усредняются (в каком то смысле, сглаживаются).\n",
    "![](dropout.gif)\n",
    "\n",
    "Давайте попробуем посмотреть, как написать сеть, состоящую из нескольких сверточных слоев на `keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D, Dropout\n",
    "\n",
    "# Все так же, создаем модель\n",
    "cnn = Sequential()\n",
    "\n",
    "# Начинаем со сверточного слоя, указывая тип активации на выходе из него и способ заполнения краев (padding)\n",
    "cnn.add(Conv2D(64, (3, 3), input_shape=input_size, activation='selu', padding='same'))\n",
    "\n",
    "# Здесь мы используем метод MaxPooling, который уменьшает размер обрабатываемого изображения, \n",
    "# выбирая из 4 пикселей 1 с максимальным значением, чтобы это быстрее считалось. (2,2) -> 1\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Слой dropout, который на каждом шаге \"выключает\" 25% случайно выбранных нейронов\n",
    "cnn.add(Dropout(0.25))\n",
    "\n",
    "# Еще сверточный слой\n",
    "cnn.add(Conv2D(32, (3, 3), input_shape=input_size, activation='selu', padding='same'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Dropout(0.5))\n",
    "\n",
    "# Последний слой необходим для классификации, но перед ним необходимо векторизовать данные\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = 'nadam',\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "history_cnn = cnn.fit(X_train[:3000], y_train[:3000],\n",
    "      batch_size=32,\n",
    "      epochs=3,\n",
    "      validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнение данных в реальном времени\n",
    "Большие модели требуют для обучения большого количества данных. Кроме того, иногда в задачах бывает крайне мало данных. В случае с изображениями в `keras` есть отличный инструмент для увеличения (раздувания) обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Задаем параметры, в рамках которых выборка может дополняться. Эти параметры сильно зависят от выборки.\n",
    "# Например, в задаче распознавания рукописных цифр отражение изображения не особо релевантно, т.к. в тестовой выборке таких встретиться не может\n",
    "shift = 0.1 # максимальное значени сдвига в долях (от 0 до 1)\n",
    "angle = 15   # максимальный угол поворота \n",
    "\n",
    "# Команда создает генератор, который при вызове в режиме реального времени генерирует необходимую подвыборку нужного размера\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, \n",
    "                             height_shift_range=shift, \n",
    "                             rotation_range=angle, \n",
    "                             horizontal_flip=False, \n",
    "                             vertical_flip=False,\n",
    "                             featurewise_center=True)\n",
    "\n",
    "# Подстраиваем генератор под наши данные\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Выберем случайно 9 картинок дополненной выборки и нарисуем их\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # создаем сетку 3х3\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    # рисуем картинки\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще, функция `ImageDataGenerator` - очень мощный инструмент препроцессинга. Например, он позволяет стандартизировать (нормализовать на среднее 0 и стандартное отклонение на 1) изображения попиксельно (достаточно укзать `featurewise_std_normalization=True` как её аргумент), а так же уменьшать избыточность матрицы изображений (`zca_whitening=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Задаем параметры, в рамках которых выборка может дополняться. Эти параметры сильно зависят от выборки.\n",
    "# Например, в задаче распознавания рукописных цифр отражение изображения не особо релевантно, т.к. в тестовой выборке таких встретиться не может\n",
    "shift = 0.1 # максимальное значени сдвига в долях (от 0 до 1)\n",
    "angle = 15   # максимальный угол поворота \n",
    "\n",
    "# Команда создает генератор, который при вызове в режиме реального времени генерирует необходимую подвыборку нужного размера\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, \n",
    "                             height_shift_range=shift, \n",
    "                             rotation_range=angle, \n",
    "                             horizontal_flip=False, \n",
    "                             vertical_flip=False,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             zca_whitening=True)\n",
    "\n",
    "# Подстраиваем генератор под наши данные\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Выберем случайно 9 картинок дополненной выборки и нарисуем их\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n",
    "    # создаем сетку 3х3\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    # рисуем картинки\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда возникает необходимость сохранить \"раздутую\" выборку. Для этого можно воспользоваться следующими командами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Задаем параметры, в рамках которых выборка может дополняться. Эти параметры сильно зависят от выборки.\n",
    "# Например, в задаче распознавания рукописных цифр отражение изображения не особо релевантно, т.к. в тестовой выборке таких встретиться не может\n",
    "shift = 0.1 # максимальное значени сдвига в долях (от 0 до 1)\n",
    "angle = 15   # максимальный угол поворота \n",
    "\n",
    "# Команда создает генератор, который при вызове в режиме реального времени генерирует необходимую подвыборку нужного размера\n",
    "datagen = ImageDataGenerator(width_shift_range=shift, \n",
    "                             height_shift_range=shift, \n",
    "                             rotation_range=angle, \n",
    "                             horizontal_flip=False, \n",
    "                             vertical_flip=False)\n",
    "\n",
    "# Подстраиваем генератор под наши данные\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Создаем папку, куда сохраним изображения\n",
    "os.makedirs('images')\n",
    "\n",
    "# Выберем случайно 9 картинок дополненной выборки и нарисуем их\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, save_to_dir='images', save_prefix='aug', save_format='png'):\n",
    "    # создаем сетку 3х3\n",
    "    for i in range(0, 9):\n",
    "        pyplot.subplot(330 + 1 + i)\n",
    "        pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "    # рисуем картинки\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общие советы по дополнению выборки:\n",
    "* Смотрите на исходную выборку\n",
    "* Смотрите на раздутую выборку\n",
    "* Пробуйте разные трансформации, иногда неожиданные сочетания могут дать заметный прирост"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning (Fine Tuning) или зачем изобретать велосипед, когда можно встать на плечи гигантов?\n",
    "\n",
    "Идея: взять уже натренированную на большом датасете большую нейросеть и переделать её под себя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Несмотря на то, что мы не будем тренировать бОльшую часть модели, код ниже будет работать долго на любом cpu\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Стандартизированный размер картинок для загружаемой сети. Это важный параметр! \n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'cats_dogs/train'\n",
    "validation_data_dir = 'cats_dogs/validation'\n",
    "nb_train_samples = 10000\n",
    "nb_validation_samples = 1000\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "\n",
    "# Загружаем модель VCG16\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# Создаем надстройку над ней для наших целей\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation='selu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Сшиваем модели в одну\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Замораживаем (не тренируем) первые слои сети, чтобы тренировать лишь оставшиеся быстрее\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Здесь неплохо указать небольшой (на порядок или два меньше стандартного) шаг алгоритма оптимизации для более аккуратного поиска.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-2, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Раздуваем данные\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Дообучаем модель\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)\n",
    "\n",
    "# ``` Важно, изображения должны быть организованы следующим образом:\n",
    "# data/\n",
    "#     train/\n",
    "#         dogs/\n",
    "#             dog001.jpg\n",
    "#             dog002.jpg\n",
    "#             ...\n",
    "#         cats/\n",
    "#             cat001.jpg\n",
    "#             cat002.jpg\n",
    "#             ...\n",
    "#     validation/\n",
    "#         dogs/\n",
    "#             dog001.jpg\n",
    "#             dog002.jpg\n",
    "#             ...\n",
    "#         cats/\n",
    "#             cat001.jpg\n",
    "#             cat002.jpg\n",
    "#             ...\n",
    "# ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "0. [2] Поиграться с кодом, доступном в семинаре, подергать за ручки, подобавлять слои, поизменять dropout rate, batch_size, тип активации, количество фильтров свертки и т.д. посмотреть результат\n",
    "0. [2] Загрузите доступный в `keras` датасет `cifar10`, постройте сверточную нейросеть, которая дает 70 % точности на тренировочной выборке. 80%? 90%?\n",
    "0. [4] Построить на `mnist` сверточную нейросеть, в которой будет расти размер сверточных фильтров, но уменьшаться их число. Натренировать такую сеть. Нарисовать полученные натренированные фильтры, посмотреть, какие паттерны они распознают в цифрах.\n",
    "0. [5] Попробуйте с помощью `keras` и нейросетей решить задачу регрессии (или классификации), не связанную с обработкой изображений: например, загрузите датасет `boston_housing`, [доступный](https://keras.io/datasets/) в `keras`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные материалы\n",
    "Хочется отметить, что на русском языке материалов пока несравненно меньше, чем на английском:\n",
    "* [Официальная документация](https://keras.io/) - библиотека отлично документирована\n",
    "* [Keras в конкретных примерах](https://github.com/tmheo/keras_exercise) - 25 отличных jupyter notebooks\n",
    "* [Упражнения и примеры в Keras и TensorFlow](https://github.com/leriomaggio/deep-learning-keras-tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stylish cell, better to compile at the beginning\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()\n",
    "\n",
    "\n",
    "# from IPython.html.services.config import ConfigManager\n",
    "# from IPython.utils.path import locate_profile\n",
    "# cm = ConfigManager(profile_dir=locate_profile(get_ipython().profile))\n",
    "# cm.update('livereveal', {\n",
    "#               'fontsize': 4,\n",
    "#               'theme': 'simple_cyr',\n",
    "#               'transition': 'zoom',\n",
    "#               'start_slideshow_at': 'selected',\n",
    "#               'height': '724',\n",
    "#               'scroll': True,\n",
    "#               'slideNumber': True\n",
    "# })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
